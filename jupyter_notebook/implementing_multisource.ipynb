{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Source : CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(r'C:\\Users\\Samruddhi More\\Desktop\\LLM BE Template\\data\\sample1.xlsx')\n",
    "\n",
    "df.to_csv('sample1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import openai\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Samruddhi More\\Desktop\\LLM BE Template\\venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the OpenAI embeddings\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the documents\n",
    "loader = CSVLoader(file_path=r'C:\\Users\\Samruddhi More\\Desktop\\LLM BE Template\\data\\1 to Many.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Samruddhi More\\Desktop\\LLM BE Template\\venv\\Lib\\site-packages\\langchain\\indexes\\vectorstore.py:129: UserWarning: Using InMemoryVectorStore as the default vectorstore.This memory store won't persist data. You should explicitlyspecify a vectorstore when using VectorstoreIndexCreator\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create an index using the loaded documents\n",
    "index_creator = VectorstoreIndexCreator(embedding=embeddings)\n",
    "docsearch = index_creator.from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Samruddhi More\\Desktop\\LLM BE Template\\venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Create a question-answering chain using the index\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", openai_api_key=openai.api_key)\n",
    "chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.vectorstore.as_retriever(), input_key=\"question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Samruddhi More\\Desktop\\LLM BE Template\\venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Pass a query to the chain\n",
    "query = \"Summarize the doument\"\n",
    "response = chain({\"question\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(response['result']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Source: PDF doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Importing necessary modules from langchain and langchain_openai\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import openai\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfpath = r'C:\\Users\\Samruddhi More\\Desktop\\LLM BE Template\\data\\Vedanta Cairn_May 2024_PO No.7300175294 (1).PDF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_processing(pdf):\n",
    "    \"\"\"\n",
    "    Process a PDF file, extracting text and splitting it into chunks.\n",
    "    \"\"\"\n",
    "    pdf_reader = PdfReader(pdf)\n",
    "        \n",
    "    text = \"\"\n",
    "    for page in pdf_reader.pages:\n",
    "        text += page.extract_text()\n",
    "        \n",
    "    # Split text into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len\n",
    "    )\n",
    "    chunks = text_splitter.split_text(text=text)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddings(chunks):\n",
    "    \"\"\"\n",
    "    Create embeddings for text chunks using OpenAI.\n",
    "    \"\"\"\n",
    "    # Initialize OpenAI embeddings\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=openai.api_key)\n",
    "    # Create vector store using FAISS\n",
    "    vector_store = FAISS.from_texts(chunks, embedding=embeddings)\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation(VectorStore):\n",
    "    \"\"\"\n",
    "    Generate responses based on prompts and embeddings.\n",
    "    \"\"\"\n",
    "    retriever = VectorStore.as_retriever()\n",
    "    \n",
    "    # Define template for prompts\n",
    "    template = \"\"\"Respond to the prompt based on the following context: {context}\n",
    "    Questions: {questions}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    # Initialize ChatOpenAI model\n",
    "    model = ChatOpenAI(openai_api_key=openai.api_key)\n",
    "    \n",
    "    # Define processing chain\n",
    "    chain = (\n",
    "        {\"context\": retriever, \"questions\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    # Prompt user for input\n",
    "    query = input(\"Insert Prompt: \")\n",
    "    \n",
    "    # Invoke the processing chain with user input\n",
    "    output = chain.invoke(query)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(generation(embeddings(chunk_processing(pdfpath))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Source: Docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Samruddhi More\\Desktop\\LLM BE Template\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Convert the docx to pdf\n",
    "from docx2pdf import convert\n",
    "\n",
    "def convert_docx_to_pdf(input_path, output_path):\n",
    "    try:\n",
    "        # Convert DOCX to PDF\n",
    "        convert(input_path, output_path)\n",
    "        print(f\"Conversion complete. PDF saved at {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete. PDF saved at document_0.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "convert_docx_to_pdf(r'C:\\Users\\Samruddhi More\\Desktop\\LLM BE Template\\data\\document_0.docx', 'document_0.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv(r'C:\\Users\\Samruddhi More\\Desktop\\LLM BE Template\\data\\1 to Many.csv')\n",
    "df.to_excel('1 to Many.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a standarad Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'tempenv (Python 3.11.7)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Samruddhi More/Desktop/LLM BE Template/tempenv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import PyPDF2\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Importing necessary modules from langchain and langchain_openai\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "#Convert the docx to pdf\n",
    "from docx2pdf import convert\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import openai\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTalk:\n",
    "\n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "\n",
    "    def source_type(self):\n",
    "        file = ''\n",
    "        folderpath = os.path.dirname(self.filepath)\n",
    "        filename = os.path.basename(self.filepath)\n",
    "        if filename.endswith('.xlsx'):\n",
    "            csvname = filename.split('.')[0] + '.csv'\n",
    "            file = os.path.join(folderpath, csvname)\n",
    "            df = pd.read_excel(self.filepath)\n",
    "            df.to_csv(file)\n",
    "        elif filename.endswith('.docx'):\n",
    "            pdfname = filename.split('.')[0] + '.pdf'\n",
    "            file = os.path.join(folderpath, pdfname)\n",
    "            convert(self.filepath, file)\n",
    "        else: \n",
    "            file = self.filepath\n",
    "\n",
    "        return file\n",
    "    \n",
    "    \n",
    "    def generate_response(self, query):\n",
    "        # Initialize the OpenAI embeddings\n",
    "        embeddings = OpenAIEmbeddings(openai_api_key=openai.api_key)\n",
    "        model_name=\"gpt-3.5-turbo-instruct\"\n",
    "        file = self.source_type()\n",
    "        response = ''\n",
    "\n",
    "        if file.endswith('.csv'):\n",
    "            # Load the documents\n",
    "            loader = CSVLoader(file_path=file)\n",
    "            # Create an index using the loaded documents\n",
    "            index_creator = VectorstoreIndexCreator(embedding=embeddings)\n",
    "            docsearch = index_creator.from_loaders([loader])\n",
    "            # Create a question-answering chain using the index\n",
    "            llm = OpenAI(model_name=model_name, openai_api_key=openai.api_key)\n",
    "            chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.vectorstore.as_retriever(), input_key=\"question\")\n",
    "            response = chain({\"question\": query})\n",
    "            response = response['result']\n",
    "        \n",
    "        elif file.lower().endswith('.pdf'):\n",
    "\n",
    "            \"\"\"\n",
    "            Process a PDF file, extracting text and splitting it into chunks.\n",
    "            \"\"\"\n",
    "            pdf_reader = PdfReader(file)\n",
    "                \n",
    "            text = \"\"\n",
    "            for page in pdf_reader.pages:\n",
    "                text += page.extract_text()\n",
    "                \n",
    "            # Split text into chunks\n",
    "            text_splitter = RecursiveCharacterTextSplitter(\n",
    "                chunk_size=1000,\n",
    "                chunk_overlap=200,\n",
    "                length_function=len\n",
    "            )\n",
    "            chunks = text_splitter.split_text(text=text)\n",
    "\n",
    "            # Create vector store using FAISS\n",
    "            vector_store = FAISS.from_texts(chunks, embedding=embeddings)\n",
    "\n",
    "            \"\"\"\n",
    "            Generate responses based on prompts and embeddings.\n",
    "            \"\"\"\n",
    "            retriever = vector_store.as_retriever()\n",
    "            \n",
    "            # Define template for prompts\n",
    "            template = \"\"\"Respond to the prompt based on the following context: {context}\n",
    "            Questions: {questions}\n",
    "            \"\"\"\n",
    "            prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "            # Initialize ChatOpenAI model\n",
    "            model = ChatOpenAI(openai_api_key=openai.api_key)\n",
    "            \n",
    "            # Define processing chain\n",
    "            chain = (\n",
    "                {\"context\": retriever, \"questions\": RunnablePassthrough()}\n",
    "                | prompt\n",
    "                | model\n",
    "                | StrOutputParser()\n",
    "            )\n",
    "            \n",
    "            # Invoke the processing chain with user input\n",
    "            response = chain.invoke(query)\n",
    "        \n",
    "        else:\n",
    "            print('The Data source format is not in required format')\n",
    "\n",
    "        return response\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Samruddhi More\\Desktop\\LLM BE Template\\tempenv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.31s/it]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Could not import faiss python package. Please install it with `pip install faiss-gpu` (for CUDA supported GPU) or `pip install faiss-cpu` (depending on Python version).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Samruddhi More\\Desktop\\LLM BE Template\\tempenv\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:55\u001b[0m, in \u001b[0;36mdependable_faiss_import\u001b[1;34m(no_avx2)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 55\u001b[0m         \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfaiss\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'faiss'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m chat \u001b[38;5;241m=\u001b[39m DataTalk(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSamruddhi More\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mLLM BE Template\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdocument_0.docx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWhat is the document about?\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 64\u001b[0m, in \u001b[0;36mDataTalk.generate_response\u001b[1;34m(self, query)\u001b[0m\n\u001b[0;32m     61\u001b[0m chunks \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_text(text\u001b[38;5;241m=\u001b[39mtext)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Create vector store using FAISS\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m \u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03mGenerate responses based on prompts and embeddings.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     69\u001b[0m retriever \u001b[38;5;241m=\u001b[39m vector_store\u001b[38;5;241m.\u001b[39mas_retriever()\n",
      "File \u001b[1;32mc:\\Users\\Samruddhi More\\Desktop\\LLM BE Template\\tempenv\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:931\u001b[0m, in \u001b[0;36mFAISS.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \n\u001b[0;32m    914\u001b[0m \u001b[38;5;124;03mThis is a user friendly interface that:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;124;03m        faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[0;32m    929\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    930\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m embedding\u001b[38;5;241m.\u001b[39membed_documents(texts)\n\u001b[1;32m--> 931\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__from\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    933\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    937\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Samruddhi More\\Desktop\\LLM BE Template\\tempenv\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:883\u001b[0m, in \u001b[0;36mFAISS.__from\u001b[1;34m(cls, texts, embeddings, embedding, metadatas, ids, normalize_L2, distance_strategy, **kwargs)\u001b[0m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__from\u001b[39m(\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    882\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FAISS:\n\u001b[1;32m--> 883\u001b[0m     faiss \u001b[38;5;241m=\u001b[39m \u001b[43mdependable_faiss_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m distance_strategy \u001b[38;5;241m==\u001b[39m DistanceStrategy\u001b[38;5;241m.\u001b[39mMAX_INNER_PRODUCT:\n\u001b[0;32m    885\u001b[0m         index \u001b[38;5;241m=\u001b[39m faiss\u001b[38;5;241m.\u001b[39mIndexFlatIP(\u001b[38;5;28mlen\u001b[39m(embeddings[\u001b[38;5;241m0\u001b[39m]))\n",
      "File \u001b[1;32mc:\\Users\\Samruddhi More\\Desktop\\LLM BE Template\\tempenv\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:57\u001b[0m, in \u001b[0;36mdependable_faiss_import\u001b[1;34m(no_avx2)\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfaiss\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import faiss python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     59\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install faiss-gpu` (for CUDA supported GPU) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `pip install faiss-cpu` (depending on Python version).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     61\u001b[0m     )\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m faiss\n",
      "\u001b[1;31mImportError\u001b[0m: Could not import faiss python package. Please install it with `pip install faiss-gpu` (for CUDA supported GPU) or `pip install faiss-cpu` (depending on Python version)."
     ]
    }
   ],
   "source": [
    "chat = DataTalk(r'C:\\Users\\Samruddhi More\\Desktop\\LLM BE Template\\data\\document_0.docx')\n",
    "chat.generate_response('What is the document about?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import fitz  # PyMuPDF\n",
    "from langchain.document_loaders import CSVLoader, PyMuPDFLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from docx2pdf import convert\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTalk:\n",
    "\n",
    "    def __init__(self, cdn_url):\n",
    "        self.cdn_url = cdn_url\n",
    "        self.filepath = self.download_file(cdn_url)\n",
    "\n",
    "    def download_file(self, url):\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            cdn_filename = url.split('/')[-1]\n",
    "            with open(cdn_filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"File {cdn_filename} downloaded successfully.\")\n",
    "            return cdn_filename\n",
    "        else:\n",
    "            raise Exception(f\"Failed to download file from {url}\")\n",
    "\n",
    "    def source_type(self):\n",
    "        file = ''\n",
    "        folderpath = os.path.dirname(self.filepath)\n",
    "        filename = os.path.basename(self.filepath)\n",
    "        if filename.endswith('.xlsx'):\n",
    "            csvname = filename.split('.')[0] + '.csv'\n",
    "            file = os.path.join(folderpath, csvname)\n",
    "            df = pd.read_excel(self.filepath)\n",
    "            df.to_csv(file, index=False)\n",
    "        elif filename.endswith('.docx'):\n",
    "            pdfname = filename.split('.')[0] + '.pdf'\n",
    "            file = os.path.join(folderpath, pdfname)\n",
    "            convert(self.filepath, file)\n",
    "        else:\n",
    "            file = self.filepath\n",
    "\n",
    "        return file\n",
    "\n",
    "    def generate_response(self, query):\n",
    "        embeddings = OpenAIEmbeddings(openai_api_key=openai.api_key)\n",
    "        model_name = \"gpt-3.5-turbo-instruct\"\n",
    "        file = self.source_type()\n",
    "        response = ''\n",
    "\n",
    "        if file.endswith('.csv'):\n",
    "            loader = CSVLoader(file_path=file)\n",
    "            index_creator = VectorstoreIndexCreator(embedding=embeddings)\n",
    "            docsearch = index_creator.from_loaders([loader])\n",
    "            llm = OpenAI(model_name=model_name, openai_api_key=openai.api_key)\n",
    "            chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.vectorstore.as_retriever(), input_key=\"question\")\n",
    "            response = chain({\"question\": query})\n",
    "            response = response['result']\n",
    "\n",
    "        elif file.lower().endswith('.pdf'):\n",
    "            pdf_reader = PdfReader(file)\n",
    "            text = \"\"\n",
    "            for page in pdf_reader.pages:\n",
    "                text += page.extract_text()\n",
    "\n",
    "            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, length_function=len)\n",
    "            chunks = text_splitter.split_text(text=text)\n",
    "\n",
    "            vector_store = FAISS.from_texts(chunks, embedding=embeddings)\n",
    "            retriever = vector_store.as_retriever()\n",
    "\n",
    "            template = \"\"\"Respond to the prompt based on the following context: {context}\n",
    "            Questions: {questions}\n",
    "            \"\"\"\n",
    "            prompt = ChatPromptTemplate.from_template(template)\n",
    "            model = ChatOpenAI(openai_api_key=openai.api_key)\n",
    "\n",
    "            chain = (\n",
    "                {\"context\": retriever, \"questions\": RunnablePassthrough()}\n",
    "                | prompt\n",
    "                | model\n",
    "                | StrOutputParser()\n",
    "            )\n",
    "\n",
    "            response = chain.invoke(query)\n",
    "\n",
    "        else:\n",
    "            print('The data source format is not in the required format.')\n",
    "\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File minimal-document.pdf downloaded successfully.\n"
     ]
    },
    {
     "ename": "PdfReadError",
     "evalue": "EOF marker not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPdfReadError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m chat \u001b[38;5;241m=\u001b[39m DataTalk(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://github.com/py-pdf/sample-files/blob/main/001-trivial/minimal-document.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWhat is the doc about?\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 52\u001b[0m, in \u001b[0;36mDataTalk.generate_response\u001b[1;34m(self, query)\u001b[0m\n\u001b[0;32m     49\u001b[0m     response \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m---> 52\u001b[0m     pdf_reader \u001b[38;5;241m=\u001b[39m \u001b[43mPdfReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m pdf_reader\u001b[38;5;241m.\u001b[39mpages:\n",
      "File \u001b[1;32mc:\\Users\\Samruddhi More\\Desktop\\LLM BE Template\\venv\\Lib\\site-packages\\PyPDF2\\_reader.py:319\u001b[0m, in \u001b[0;36mPdfReader.__init__\u001b[1;34m(self, stream, strict, password)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(stream, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[0;32m    318\u001b[0m         stream \u001b[38;5;241m=\u001b[39m BytesIO(fh\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m--> 319\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m stream\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_override_encryption \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Samruddhi More\\Desktop\\LLM BE Template\\venv\\Lib\\site-packages\\PyPDF2\\_reader.py:1415\u001b[0m, in \u001b[0;36mPdfReader.read\u001b[1;34m(self, stream)\u001b[0m\n\u001b[0;32m   1413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, stream: StreamType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1414\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_basic_validation(stream)\n\u001b[1;32m-> 1415\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_find_eof_marker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1416\u001b[0m     startxref \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_startxref_pos(stream)\n\u001b[0;32m   1418\u001b[0m     \u001b[38;5;66;03m# check and eventually correct the startxref only in not strict\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Samruddhi More\\Desktop\\LLM BE Template\\venv\\Lib\\site-packages\\PyPDF2\\_reader.py:1471\u001b[0m, in \u001b[0;36mPdfReader._find_eof_marker\u001b[1;34m(self, stream)\u001b[0m\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m line[:\u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124mEOF\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1470\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;241m<\u001b[39m last_mb:\n\u001b[1;32m-> 1471\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m PdfReadError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEOF marker not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1472\u001b[0m     line \u001b[38;5;241m=\u001b[39m read_previous_line(stream)\n",
      "\u001b[1;31mPdfReadError\u001b[0m: EOF marker not found"
     ]
    }
   ],
   "source": [
    "chat = DataTalk('https://github.com/py-pdf/sample-files/blob/main/001-trivial/minimal-document.pdf')\n",
    "chat.generate_response('What is the doc about?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Samruddhi More\\Desktop\\LLM BE Template\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import PyPDF2\n",
    "from PyPDF2 import PdfReader\n",
    "from docx2pdf import convert\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Failed to download file from https://github.com/anupsawant/PRDashboard/raw/main/dashboard/data/D0_Monthly.xlsx",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 106\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m chat \u001b[38;5;241m=\u001b[39m \u001b[43mDataTalk\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://github.com/anupsawant/PRDashboard/raw/main/dashboard/data/D0_Monthly.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m response \u001b[38;5;241m=\u001b[39m chat\u001b[38;5;241m.\u001b[39mgenerate_response(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhat is the doc about?\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m, in \u001b[0;36mDataTalk.__init__\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, url):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl \u001b[38;5;241m=\u001b[39m url\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 16\u001b[0m, in \u001b[0;36mDataTalk.download_file\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m filename\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to download file from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: Failed to download file from https://github.com/anupsawant/PRDashboard/raw/main/dashboard/data/D0_Monthly.xlsx"
     ]
    }
   ],
   "source": [
    "class DataTalk:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.filepath = self.download_file(url)\n",
    "\n",
    "    def download_file(self, url):\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            # Extract the filename from the URL and save it in the current directory\n",
    "            filename = url.split(\"/\")[-1].split(\"?\")[0]  # Remove query parameters if any\n",
    "            with open(filename, \"wb\") as file:\n",
    "                file.write(response.content)\n",
    "            return filename\n",
    "        else:\n",
    "            raise Exception(f\"Failed to download file from {url}\")\n",
    "\n",
    "    def source_type(self):\n",
    "        file = ''\n",
    "        folderpath = os.path.dirname(self.filepath)\n",
    "        filename = os.path.basename(self.filepath)\n",
    "        if filename.endswith('.xlsx'):\n",
    "            csvname = filename.split('.')[0] + '.csv'\n",
    "            file = os.path.join(folderpath, csvname)\n",
    "            df = pd.read_excel(self.filepath)\n",
    "            df.to_csv(file)\n",
    "        elif filename.endswith('.docx'):\n",
    "            pdfname = filename.split('.')[0] + '.pdf'\n",
    "            file = os.path.join(folderpath, pdfname)\n",
    "            convert(self.filepath, file)\n",
    "        else: \n",
    "            file = self.filepath\n",
    "\n",
    "        return file\n",
    "\n",
    "    def generate_response(self, query):\n",
    "        # Initialize the OpenAI embeddings\n",
    "        embeddings = OpenAIEmbeddings(openai_api_key=openai.api_key)\n",
    "        model_name = \"gpt-3.5-turbo-instruct\"\n",
    "        file = self.source_type()\n",
    "        response = ''\n",
    "\n",
    "        if file.endswith('.csv'):\n",
    "            # Load the documents\n",
    "            loader = CSVLoader(file_path=file)\n",
    "            # Create an index using the loaded documents\n",
    "            index_creator = VectorstoreIndexCreator(embedding=embeddings)\n",
    "            docsearch = index_creator.from_loaders([loader])\n",
    "            # Create a question-answering chain using the index\n",
    "            llm = OpenAI(model_name=model_name, openai_api_key=openai.api_key)\n",
    "            chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.vectorstore.as_retriever(), input_key=\"question\")\n",
    "            response = chain({\"question\": query})\n",
    "            response = response['result']\n",
    "\n",
    "        elif file.lower().endswith('.pdf'):\n",
    "            \"\"\"\n",
    "            Process a PDF file, extracting text and splitting it into chunks.\n",
    "            \"\"\"\n",
    "            pdf_reader = PdfReader(file)\n",
    "            text = \"\"\n",
    "            for page in pdf_reader.pages:\n",
    "                text += page.extract_text()\n",
    "            \n",
    "            # Split text into chunks\n",
    "            text_splitter = RecursiveCharacterTextSplitter(\n",
    "                chunk_size=1000,\n",
    "                chunk_overlap=200,\n",
    "                length_function=len\n",
    "            )\n",
    "            chunks = text_splitter.split_text(text=text)\n",
    "\n",
    "            # Create vector store using FAISS\n",
    "            vector_store = FAISS.from_texts(chunks, embedding=embeddings)\n",
    "\n",
    "            \"\"\"\n",
    "            Generate responses based on prompts and embeddings.\n",
    "            \"\"\"\n",
    "            retriever = vector_store.as_retriever()\n",
    "            \n",
    "            # Define template for prompts\n",
    "            template = \"\"\"Respond to the prompt based on the following context: {context}\n",
    "            Questions: {questions}\n",
    "            \"\"\"\n",
    "            prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "            # Initialize ChatOpenAI model\n",
    "            model = ChatOpenAI(openai_api_key=openai.api_key)\n",
    "            \n",
    "            # Define processing chain\n",
    "            chain = (\n",
    "                {\"context\": retriever, \"questions\": RunnablePassthrough()}\n",
    "                | prompt\n",
    "                | model\n",
    "                | StrOutputParser()\n",
    "            )\n",
    "            \n",
    "            # Invoke the processing chain with user input\n",
    "            response = chain.invoke(query)\n",
    "        \n",
    "        else:\n",
    "            print('The data source format is not in required format')\n",
    "\n",
    "        return response\n",
    "\n",
    "# Example usage\n",
    "chat = DataTalk('https://github.com/anupsawant/PRDashboard/raw/main/dashboard/data/D0_Monthly.xlsx')\n",
    "response = chat.generate_response('What is the doc about?')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\Samruddhi More\\\\Desktop\\\\LLM BE Template\\\\tempenv\\\\Lib\\\\site-packages\\\\~okenizers\\\\tokenizers.cp311-win_amd64.pyd'\n",
      "Check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Obtaining dependency information for sentence_transformers from https://files.pythonhosted.org/packages/58/4b/922436953394e1bfda05e4bf1fe0e80f609770f256c59a9df7a9254f3e0d/sentence_transformers-3.0.1-py3-none-any.whl.metadata\n",
      "  Using cached sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers<5.0.0,>=4.34.0 (from sentence_transformers)\n",
      "  Obtaining dependency information for transformers<5.0.0,>=4.34.0 from https://files.pythonhosted.org/packages/75/35/07c9879163b603f0e464b0f6e6e628a2340cfc7cdc5ca8e7d52d776710d4/transformers-4.44.2-py3-none-any.whl.metadata\n",
      "  Using cached transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from sentence_transformers) (4.66.4)\n",
      "Collecting torch>=1.11.0 (from sentence_transformers)\n",
      "  Obtaining dependency information for torch>=1.11.0 from https://files.pythonhosted.org/packages/5a/6a/775b93d6888c31f1f1fc457e4f5cc89f0984412d5dcdef792b8f2aa6e812/torch-2.4.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached torch-2.4.1-cp311-cp311-win_amd64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from sentence_transformers) (1.26.4)\n",
      "Collecting scikit-learn (from sentence_transformers)\n",
      "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/5d/55/0403bf2031250ac982c8053397889fbc5a3a2b3798b913dae4f51c3af6a4/scikit_learn-1.5.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached scikit_learn-1.5.1-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting scipy (from sentence_transformers)\n",
      "  Obtaining dependency information for scipy from https://files.pythonhosted.org/packages/ea/c2/5ecadc5fcccefaece775feadcd795060adf5c3b29a883bff0e678cfe89af/scipy-1.14.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached scipy-1.14.1-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from sentence_transformers) (0.24.6)\n",
      "Collecting Pillow (from sentence_transformers)\n",
      "  Obtaining dependency information for Pillow from https://files.pythonhosted.org/packages/c1/d0/5866318eec2b801cdb8c82abf190c8343d8a1cd8bf5a0c17444a6f268291/pillow-10.4.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached pillow-10.4.0-cp311-cp311-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.16.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (1.13.2)\n",
      "Collecting networkx (from torch>=1.11.0->sentence_transformers)\n",
      "  Obtaining dependency information for networkx from https://files.pythonhosted.org/packages/38/e9/5f72929373e1a0e8d142a130f3f97e6ff920070f87f91c4e13e40e0fba5a/networkx-3.3-py3-none-any.whl.metadata\n",
      "  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence_transformers)\n",
      "  Obtaining dependency information for jinja2 from https://files.pythonhosted.org/packages/31/80/3a54838c3fb461f6fec263ebf3a3a41771bd05190238de3486aae8540c36/jinja2-3.1.4-py3-none-any.whl.metadata\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2024.5.15)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.34.0->sentence_transformers)\n",
      "  Obtaining dependency information for safetensors>=0.4.1 from https://files.pythonhosted.org/packages/6d/41/948c96c8a7e9fef57c2e051f1871c108a6dbbc6d285598bdb1d89b98617c/safetensors-0.4.5-cp311-none-win_amd64.whl.metadata\n",
      "  Using cached safetensors-0.4.5-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers<5.0.0,>=4.34.0->sentence_transformers)\n",
      "  Obtaining dependency information for tokenizers<0.20,>=0.19 from https://files.pythonhosted.org/packages/65/8e/6d7d72b28f22c422cff8beae10ac3c2e4376b9be721ef8167b7eecd1da62/tokenizers-0.19.1-cp311-none-win_amd64.whl.metadata\n",
      "  Using cached tokenizers-0.19.1-cp311-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence_transformers)\n",
      "  Obtaining dependency information for threadpoolctl>=3.1.0 from https://files.pythonhosted.org/packages/4b/2c/ffbf7a134b9ab11a67b0cf0726453cedd9c5043a4fe7a35d1cefa9a1bcfb/threadpoolctl-3.5.0-py3-none-any.whl.metadata\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence_transformers)\n",
      "  Obtaining dependency information for MarkupSafe>=2.0 from https://files.pythonhosted.org/packages/b7/a2/c78a06a9ec6d04b3445a949615c4c7ed86a0b2eb68e44e7541b9d57067cc/MarkupSafe-2.1.5-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached MarkupSafe-2.1.5-cp311-cp311-win_amd64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.6.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Using cached sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
      "Using cached torch-2.4.1-cp311-cp311-win_amd64.whl (199.4 MB)\n",
      "Using cached transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "Using cached pillow-10.4.0-cp311-cp311-win_amd64.whl (2.6 MB)\n",
      "Using cached scikit_learn-1.5.1-cp311-cp311-win_amd64.whl (11.0 MB)\n",
      "Using cached scipy-1.14.1-cp311-cp311-win_amd64.whl (44.8 MB)\n",
      "Using cached safetensors-0.4.5-cp311-none-win_amd64.whl (285 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached tokenizers-0.19.1-cp311-none-win_amd64.whl (2.2 MB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Using cached MarkupSafe-2.1.5-cp311-cp311-win_amd64.whl (17 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, safetensors, Pillow, networkx, MarkupSafe, scikit-learn, jinja2, torch, tokenizers, transformers, sentence_transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.20.0\n",
      "    Uninstalling tokenizers-0.20.0:\n",
      "      Successfully uninstalled tokenizers-0.20.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Obtaining dependency information for pypdf from https://files.pythonhosted.org/packages/3c/60/eccdd92dd4af3e4bea6d6a342f7588c618a15b9bec4b968af581e498bcc4/pypdf-4.3.1-py3-none-any.whl.metadata\n",
      "  Using cached pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Using cached pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-4.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unstructured\n",
      "  Obtaining dependency information for unstructured from https://files.pythonhosted.org/packages/58/7b/93126eed91753d65d0c07e9f4c80bd715b6b6003f139483024ae00749aa2/unstructured-0.15.9-py3-none-any.whl.metadata\n",
      "  Downloading unstructured-0.15.9-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting chardet (from unstructured)\n",
      "  Obtaining dependency information for chardet from https://files.pythonhosted.org/packages/38/6f/f5fbc992a329ee4e0f288c1fe0e2ad9485ed064cac731ed2fe47dcc38cbf/chardet-5.2.0-py3-none-any.whl.metadata\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting filetype (from unstructured)\n",
      "  Obtaining dependency information for filetype from https://files.pythonhosted.org/packages/18/79/1b8fa1bb3568781e84c9200f951c735f3f157429f44be0495da55894d620/filetype-1.2.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting python-magic (from unstructured)\n",
      "  Obtaining dependency information for python-magic from https://files.pythonhosted.org/packages/6c/73/9f872cb81fc5c3bb48f7227872c28975f998f3e7c2b1c16e95e6432bbb90/python_magic-0.4.27-py2.py3-none-any.whl.metadata\n",
      "  Using cached python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting lxml (from unstructured)\n",
      "  Obtaining dependency information for lxml from https://files.pythonhosted.org/packages/c3/b5/91c2249bfac02ee514ab135e9304b89d55967be7e53e94a879b74eec7a5c/lxml-5.3.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached lxml-5.3.0-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting nltk (from unstructured)\n",
      "  Obtaining dependency information for nltk from https://files.pythonhosted.org/packages/4d/66/7d9e26593edda06e8cb531874633f7c2372279c3b0f46235539fe546df8b/nltk-3.9.1-py3-none-any.whl.metadata\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting tabulate (from unstructured)\n",
      "  Obtaining dependency information for tabulate from https://files.pythonhosted.org/packages/40/44/4a5f08c96eb108af5cb50b41f76142f0afa346dfa99d5296fe7202a11854/tabulate-0.9.0-py3-none-any.whl.metadata\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from unstructured) (2.32.3)\n",
      "Collecting beautifulsoup4 (from unstructured)\n",
      "  Obtaining dependency information for beautifulsoup4 from https://files.pythonhosted.org/packages/b1/fe/e8c672695b37eecc5cbf43e1d0638d88d66ba3a44c4d321c796f4e59167f/beautifulsoup4-4.12.3-py3-none-any.whl.metadata\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting emoji (from unstructured)\n",
      "  Obtaining dependency information for emoji from https://files.pythonhosted.org/packages/e6/90/20ad30babfa8f2b5ab46281d8e17bdfdbb3ac294cda14d525b9c2d958846/emoji-2.12.1-py3-none-any.whl.metadata\n",
      "  Using cached emoji-2.12.1-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from unstructured) (0.6.7)\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Obtaining dependency information for python-iso639 from https://files.pythonhosted.org/packages/01/08/5e649cf18dec750d498c53c6c8eb1d9790752ebd50fa7f7e69cc0c277cfe/python_iso639-2024.4.27-py3-none-any.whl.metadata\n",
      "  Using cached python_iso639-2024.4.27-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langdetect (from unstructured)\n",
      "  Using cached langdetect-1.0.9-py3-none-any.whl\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from unstructured) (1.26.4)\n",
      "Collecting rapidfuzz (from unstructured)\n",
      "  Obtaining dependency information for rapidfuzz from https://files.pythonhosted.org/packages/64/d9/c86f7b247b1603cae62d5d39cbc12f5baaeb34e80fd00c7211fe43157a66/rapidfuzz-3.9.7-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached rapidfuzz-3.9.7-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting backoff (from unstructured)\n",
      "  Obtaining dependency information for backoff from https://files.pythonhosted.org/packages/df/73/b6e24bd22e6720ca8ee9a85a0c4a2971af8497d8f3193fa05390cbd46e09/backoff-2.2.1-py3-none-any.whl.metadata\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from unstructured) (4.12.2)\n",
      "Collecting unstructured-client (from unstructured)\n",
      "  Obtaining dependency information for unstructured-client from https://files.pythonhosted.org/packages/65/0b/c4a16722f148fa855d4297b8fa019a2d3c075cfc0332ddca56af45e36d16/unstructured_client-0.25.7-py3-none-any.whl.metadata\n",
      "  Using cached unstructured_client-0.25.7-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting wrapt (from unstructured)\n",
      "  Obtaining dependency information for wrapt from https://files.pythonhosted.org/packages/cf/c3/0084351951d9579ae83a3d9e38c140371e4c6b038136909235079f2e6e78/wrapt-1.16.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached wrapt-1.16.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from unstructured) (4.66.4)\n",
      "Requirement already satisfied: psutil in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from unstructured) (6.0.0)\n",
      "Collecting python-oxmsg (from unstructured)\n",
      "  Obtaining dependency information for python-oxmsg from https://files.pythonhosted.org/packages/d4/c8/fb23e1e7723ba9200b75bc121f22f67498ae098a202f1646acc4f6a54f5c/python_oxmsg-0.0.1-py3-none-any.whl.metadata\n",
      "  Downloading python_oxmsg-0.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->unstructured)\n",
      "  Obtaining dependency information for soupsieve>1.2 from https://files.pythonhosted.org/packages/d1/c2/fe97d779f3ef3b15f05c94a2f1e3d21732574ed441687474db9d342a7315/soupsieve-2.6-py3-none-any.whl.metadata\n",
      "  Using cached soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from dataclasses-json->unstructured) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: six in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from langdetect->unstructured) (1.16.0)\n",
      "Collecting click (from nltk->unstructured)\n",
      "  Obtaining dependency information for click from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk->unstructured)\n",
      "  Obtaining dependency information for joblib from https://files.pythonhosted.org/packages/91/29/df4b9b42f2be0b623cbd5e2140cafcaa2bef0759a00b7b70104dcfe2fb51/joblib-1.4.2-py3-none-any.whl.metadata\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from nltk->unstructured) (2024.5.15)\n",
      "Collecting olefile (from python-oxmsg->unstructured)\n",
      "  Obtaining dependency information for olefile from https://files.pythonhosted.org/packages/17/d3/b64c356a907242d719fc668b71befd73324e47ab46c8ebbbede252c154b2/olefile-0.47-py2.py3-none-any.whl.metadata\n",
      "  Using cached olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from requests->unstructured) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from requests->unstructured) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from requests->unstructured) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from requests->unstructured) (2024.6.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from tqdm->unstructured) (0.4.6)\n",
      "Collecting deepdiff>=6.0 (from unstructured-client->unstructured)\n",
      "  Obtaining dependency information for deepdiff>=6.0 from https://files.pythonhosted.org/packages/06/46/01673060e83277a863baf0909b387cd809865cba2d5e7213db76516bedd9/deepdiff-8.0.1-py3-none-any.whl.metadata\n",
      "  Using cached deepdiff-8.0.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from unstructured-client->unstructured) (0.27.0)\n",
      "Collecting jsonpath-python>=1.0.6 (from unstructured-client->unstructured)\n",
      "  Obtaining dependency information for jsonpath-python>=1.0.6 from https://files.pythonhosted.org/packages/16/8a/d63959f4eff03893a00e6e63592e3a9f15b9266ed8e0275ab77f8c7dbc94/jsonpath_python-1.0.6-py3-none-any.whl.metadata\n",
      "  Using cached jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from unstructured-client->unstructured) (1.0.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from unstructured-client->unstructured) (1.6.0)\n",
      "Requirement already satisfied: packaging>=23.1 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from unstructured-client->unstructured) (24.1)\n",
      "Requirement already satisfied: pypdf>=4.0 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from unstructured-client->unstructured) (4.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from unstructured-client->unstructured) (2.9.0.post0)\n",
      "Collecting requests-toolbelt>=1.0.0 (from unstructured-client->unstructured)\n",
      "  Obtaining dependency information for requests-toolbelt>=1.0.0 from https://files.pythonhosted.org/packages/3f/51/d4db610ef29373b879047326cbf6fa98b6c1969d6f6dc423279de2b1be2c/requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting orderly-set==5.2.2 (from deepdiff>=6.0->unstructured-client->unstructured)\n",
      "  Obtaining dependency information for orderly-set==5.2.2 from https://files.pythonhosted.org/packages/69/71/6f9554919da608cb5bcf709822a9644ba4785cc7856e01ea375f6d808774/orderly_set-5.2.2-py3-none-any.whl.metadata\n",
      "  Using cached orderly_set-5.2.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured) (0.14.0)\n",
      "Downloading unstructured-0.15.9-py3-none-any.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.2/2.1 MB 7.6 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.8/2.1 MB 10.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.3/2.1 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.5/2.1 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 9.6 MB/s eta 0:00:00\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Using cached emoji-2.12.1-py3-none-any.whl (431 kB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Using cached lxml-5.3.0-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached python_iso639-2024.4.27-py3-none-any.whl (274 kB)\n",
      "Using cached python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading python_oxmsg-0.0.1-py3-none-any.whl (31 kB)\n",
      "Using cached rapidfuzz-3.9.7-cp311-cp311-win_amd64.whl (1.7 MB)\n",
      "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Using cached unstructured_client-0.25.7-py3-none-any.whl (45 kB)\n",
      "Using cached wrapt-1.16.0-cp311-cp311-win_amd64.whl (37 kB)\n",
      "Using cached deepdiff-8.0.1-py3-none-any.whl (82 kB)\n",
      "Using cached orderly_set-5.2.2-py3-none-any.whl (11 kB)\n",
      "Using cached jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "   ---------------------------------------- 0.0/114.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 114.6/114.6 kB ? eta 0:00:00\n",
      "Installing collected packages: filetype, wrapt, tabulate, soupsieve, rapidfuzz, python-magic, python-iso639, orderly-set, olefile, lxml, langdetect, jsonpath-python, joblib, emoji, click, chardet, backoff, requests-toolbelt, python-oxmsg, nltk, deepdiff, beautifulsoup4, unstructured-client, unstructured\n",
      "Successfully installed backoff-2.2.1 beautifulsoup4-4.12.3 chardet-5.2.0 click-8.1.7 deepdiff-8.0.1 emoji-2.12.1 filetype-1.2.0 joblib-1.4.2 jsonpath-python-1.0.6 langdetect-1.0.9 lxml-5.3.0 nltk-3.9.1 olefile-0.47 orderly-set-5.2.2 python-iso639-2024.4.27 python-magic-0.4.27 python-oxmsg-0.0.1 rapidfuzz-3.9.7 requests-toolbelt-1.0.0 soupsieve-2.6 tabulate-0.9.0 unstructured-0.15.9 unstructured-client-0.25.7 wrapt-1.16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-chroma\n",
      "  Obtaining dependency information for langchain-chroma from https://files.pythonhosted.org/packages/65/22/fa0a518618d769dacc732cf3a623debb04720949e1a5f26d02756c19449f/langchain_chroma-0.1.3-py3-none-any.whl.metadata\n",
      "  Using cached langchain_chroma-0.1.3-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0 (from langchain-chroma)\n",
      "  Obtaining dependency information for chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0 from https://files.pythonhosted.org/packages/3e/c9/d55602e07bb839c578f4698b92db7ea88c1aa92f69d4c86076c1597e451b/chromadb-0.5.3-py3-none-any.whl.metadata\n",
      "  Using cached chromadb-0.5.3-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting fastapi<1,>=0.95.2 (from langchain-chroma)\n",
      "  Obtaining dependency information for fastapi<1,>=0.95.2 from https://files.pythonhosted.org/packages/d0/80/17037f322c280efbc623e341358d38d0299c6ee899d619a879b3593aa6da/fastapi-0.114.0-py3-none-any.whl.metadata\n",
      "  Using cached fastapi-0.114.0-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.1.40 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from langchain-chroma) (0.2.10)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from langchain-chroma) (1.26.4)\n",
      "Collecting build>=1.0.3 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for build>=1.0.3 from https://files.pythonhosted.org/packages/91/fd/e4bda6228637ecae5732162b5ac2a5a822e2ba8e546eb4997cde51b231a3/build-1.2.2-py3-none-any.whl.metadata\n",
      "  Using cached build-1.2.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: requests>=2.28 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.32.3)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.8.0)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for chroma-hnswlib==0.7.3 from https://files.pythonhosted.org/packages/d2/32/a91850c7aa8a34f61838913155103808fe90da6f1ea4302731b59e9ba6f2/chroma_hnswlib-0.7.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached chroma_hnswlib-0.7.3-cp311-cp311-win_amd64.whl.metadata (262 bytes)\n",
      "Collecting uvicorn[standard]>=0.18.3 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for uvicorn[standard]>=0.18.3 from https://files.pythonhosted.org/packages/f5/8e/cdc7d6263db313030e4c257dd5ba3909ebc4e4fb53ad62d5f09b1a2f5458/uvicorn-0.30.6-py3-none-any.whl.metadata\n",
      "  Using cached uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting posthog>=2.4.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for posthog>=2.4.0 from https://files.pythonhosted.org/packages/e2/84/8fff10f1bcc41d53c04bc573c2b6878d1d85639d78fd7c261671eb3c0e3e/posthog-3.6.5-py2.py3-none-any.whl.metadata\n",
      "  Using cached posthog-3.6.5-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.12.2)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for onnxruntime>=1.14.1 from https://files.pythonhosted.org/packages/1e/f5/9d995a685f97508b3254f17015b4a78641b0625e79480a7aed7a7a105d7c/onnxruntime-1.19.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached onnxruntime-1.19.2-cp311-cp311-win_amd64.whl.metadata (4.7 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for opentelemetry-api>=1.2.0 from https://files.pythonhosted.org/packages/fb/1f/737dcdbc9fea2fa96c1b392ae47275165a7c641663fbb08a8d252968eed2/opentelemetry_api-1.27.0-py3-none-any.whl.metadata\n",
      "  Using cached opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for opentelemetry-exporter-otlp-proto-grpc>=1.2.0 from https://files.pythonhosted.org/packages/8d/80/32217460c2c64c0568cea38410124ff680a9b65f6732867bbf857c4d8626/opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl.metadata\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for opentelemetry-instrumentation-fastapi>=0.41b0 from https://files.pythonhosted.org/packages/ee/50/745ab075a3041b7a5f29a579d2c28eaad54f64b4589d8f9fd364c62cf0f3/opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl.metadata\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for opentelemetry-sdk>=1.2.0 from https://files.pythonhosted.org/packages/c1/bd/a6602e71e315055d63b2ff07172bd2d012b4cba2d4e00735d74ba42fc4d6/opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata\n",
      "  Using cached opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for tokenizers>=0.13.2 from https://files.pythonhosted.org/packages/c0/3c/9228601e180b177755fd9f35cbb229c13f1919a55f07a602b1bd7d716470/tokenizers-0.20.0-cp311-none-win_amd64.whl.metadata\n",
      "  Using cached tokenizers-0.20.0-cp311-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.66.4)\n",
      "Collecting overrides>=7.3.1 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for overrides>=7.3.1 from https://files.pythonhosted.org/packages/2c/ab/fc8290c6a4c722e5514d80f62b2dc4c4df1a68a41d1364e625c35990fcf3/overrides-7.7.0-py3-none-any.whl.metadata\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for importlib-resources from https://files.pythonhosted.org/packages/e1/6a/4604f9ae2fa62ef47b9de2fa5ad599589d28c9fd1d335f32759813dfa91e/importlib_resources-6.4.5-py3-none-any.whl.metadata\n",
      "  Using cached importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for grpcio>=1.58.0 from https://files.pythonhosted.org/packages/45/86/cc31ad1578abd322c403b7425e6b50eb8a48a8f96c2e558dacd0ef472dc1/grpcio-1.66.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached grpcio-1.66.1-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for bcrypt>=4.0.1 from https://files.pythonhosted.org/packages/1c/2a/c74052e54162ec639266d91539cca7cbf3d1d3b8b36afbfeaee0ea6a1702/bcrypt-4.2.0-cp39-abi3-win_amd64.whl.metadata\n",
      "  Using cached bcrypt-4.2.0-cp39-abi3-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for typer>=0.9.0 from https://files.pythonhosted.org/packages/a8/2b/886d13e742e514f704c33c4caa7df0f3b89e5a25ef8db02aa9ca3d9535d5/typer-0.12.5-py3-none-any.whl.metadata\n",
      "  Using cached typer-0.12.5-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for kubernetes>=28.1.0 from https://files.pythonhosted.org/packages/62/a1/2027ddede72d33be2effc087580aeba07e733a7360780ae87226f1f91bd8/kubernetes-30.1.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached kubernetes-30.1.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (8.4.2)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (6.0.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.10.5)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.27.0)\n",
      "Collecting starlette<0.39.0,>=0.37.2 (from fastapi<1,>=0.95.2->langchain-chroma)\n",
      "  Obtaining dependency information for starlette<0.39.0,>=0.37.2 from https://files.pythonhosted.org/packages/90/1a/8853ba4cea1ec99535ac9be5795a50ca92cddd04d57bbaa56e866cb7548c/starlette-0.38.5-py3-none-any.whl.metadata\n",
      "  Using cached starlette-0.38.5-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from langchain-core<0.3,>=0.1.40->langchain-chroma) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from langchain-core<0.3,>=0.1.40->langchain-chroma) (0.1.83)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from langchain-core<0.3,>=0.1.40->langchain-chroma) (24.1)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for pyproject_hooks from https://files.pythonhosted.org/packages/ae/f3/431b9d5fe7d14af7a32340792ef43b8a714e7726f1d7b69cc4e8e7a3f1d7/pyproject_hooks-1.1.0-py3-none-any.whl.metadata\n",
      "  Using cached pyproject_hooks-1.1.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.4.6)\n",
      "Requirement already satisfied: anyio in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.4.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.40->langchain-chroma) (3.0.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.9.0.post0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for google-auth>=1.0.1 from https://files.pythonhosted.org/packages/bb/fb/9af9e3f2996677bdda72734482934fe85a3abde174e5f0783ac2f817ba98/google_auth-2.34.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached google_auth-2.34.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.8.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for requests-oauthlib from https://files.pythonhosted.org/packages/3b/5d/63d4ae3b9daea098d5d6f5da83984853c1bbacd5dc826764b249fe119d24/requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for oauthlib>=3.2.2 from https://files.pythonhosted.org/packages/7e/80/cab10959dc1faead58dc8384a781dfbf93cb4d33d50988f7a69f1b7c9bbe/oauthlib-3.2.2-py3-none-any.whl.metadata\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.2.2)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for coloredlogs from https://files.pythonhosted.org/packages/a7/06/3d6badcf13db419e25b07041d9c7b4a2c331d3f4e7134445ec5df57714cd/coloredlogs-15.0.1-py2.py3-none-any.whl.metadata\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (24.3.25)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for protobuf from https://files.pythonhosted.org/packages/de/f7/e7e03be7e7307123f6467080f283e484de7e892db54dd9a46f057d08c9ee/protobuf-5.28.0-cp310-abi3-win_amd64.whl.metadata\n",
      "  Using cached protobuf-5.28.0-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: sympy in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.13.2)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for deprecated>=1.2.6 from https://files.pythonhosted.org/packages/20/8d/778b7d51b981a96554f29136cd59ca7880bf58094338085bcf2a979a0e6a/Deprecated-1.2.14-py2.py3-none-any.whl.metadata\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting importlib-metadata<=8.4.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for importlib-metadata<=8.4.0,>=6.0 from https://files.pythonhosted.org/packages/c0/14/362d31bf1076b21e1bcdcb0dc61944822ff263937b804a79231df2774d28/importlib_metadata-8.4.0-py3-none-any.whl.metadata\n",
      "  Using cached importlib_metadata-8.4.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for googleapis-common-protos~=1.52 from https://files.pythonhosted.org/packages/ec/08/49bfe7cf737952cc1a9c43e80cc258ed45dad7f183c5b8276fc94cb3862d/googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for opentelemetry-exporter-otlp-proto-common==1.27.0 from https://files.pythonhosted.org/packages/41/27/4610ab3d9bb3cde4309b6505f98b3aabca04a26aa480aa18cede23149837/opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl.metadata\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for opentelemetry-proto==1.27.0 from https://files.pythonhosted.org/packages/94/56/3d2d826834209b19a5141eed717f7922150224d1a982385d19a9444cbf8d/opentelemetry_proto-1.27.0-py3-none-any.whl.metadata\n",
      "  Using cached opentelemetry_proto-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for protobuf from https://files.pythonhosted.org/packages/0c/d4/589d673ada9c4c62d5f155218d7ff7ac796efb9c6af95b0bd29d438ae16e/protobuf-4.25.4-cp310-abi3-win_amd64.whl.metadata\n",
      "  Using cached protobuf-4.25.4-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for opentelemetry-instrumentation-asgi==0.48b0 from https://files.pythonhosted.org/packages/db/74/a0e0d38622856597dd8e630f2bd793760485eb165708e11b8be1696bbb5a/opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl.metadata\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for opentelemetry-instrumentation==0.48b0 from https://files.pythonhosted.org/packages/0a/7f/405c41d4f359121376c9d5117dcf68149b8122d3f6c718996d037bd4d800/opentelemetry_instrumentation-0.48b0-py3-none-any.whl.metadata\n",
      "  Using cached opentelemetry_instrumentation-0.48b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for opentelemetry-semantic-conventions==0.48b0 from https://files.pythonhosted.org/packages/b7/7a/4f0063dbb0b6c971568291a8bc19a4ca70d3c185db2d956230dd67429dfc/opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata\n",
      "  Using cached opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-util-http==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for opentelemetry-util-http==0.48b0 from https://files.pythonhosted.org/packages/ad/2e/36097c0a4d0115b8c7e377c90bab7783ac183bc5cb4071308f8959454311/opentelemetry_util_http-0.48b0-py3-none-any.whl.metadata\n",
      "  Using cached opentelemetry_util_http-0.48b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (65.5.0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.16.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from pydantic>=1.9->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.0 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from pydantic>=1.9->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.20.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from requests>=2.28->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.3.2)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/b9/8f/d6718641c14d98a5848c6a24d2376028d292074ffade0702940a4b1dde76/huggingface_hub-0.24.6-py3-none-any.whl.metadata\n",
      "  Using cached huggingface_hub-0.24.6-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for shellingham>=1.3.0 from https://files.pythonhosted.org/packages/e0/f9/0595336914c5619e5f28a1fb793285925a8cd4b432c9da0a987836c7f822/shellingham-1.5.4-py2.py3-none-any.whl.metadata\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for rich>=10.11.0 from https://files.pythonhosted.org/packages/c7/d9/c2a126eeae791e90ea099d05cb0515feea3688474b978343f3cdcfe04523/rich-13.8.0-py3-none-any.whl.metadata\n",
      "  Using cached rich-13.8.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for httptools>=0.5.0 from https://files.pythonhosted.org/packages/14/e4/20d28dfe7f5b5603b6b04c33bb88662ad749de51f0c539a561f235f42666/httptools-0.6.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached httptools-0.6.1-cp311-cp311-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.0.1)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for watchfiles>=0.13 from https://files.pythonhosted.org/packages/8a/8b/badd9247d6ec25f5f634a9b3d0d92e39c045824ec7e8afcedca8ee52c1e2/watchfiles-0.24.0-cp311-none-win_amd64.whl.metadata\n",
      "  Using cached watchfiles-0.24.0-cp311-none-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (13.0.1)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for cachetools<6.0,>=2.0.0 from https://files.pythonhosted.org/packages/a4/07/14f8ad37f2d12a5ce41206c21820d8cb6561b728e51fad4530dff0552a67/cachetools-5.5.0-py3-none-any.whl.metadata\n",
      "  Using cached cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for pyasn1-modules>=0.2.1 from https://files.pythonhosted.org/packages/13/68/8906226b15ef38e71dc926c321d2fe99de8048e9098b5dfd38343011c886/pyasn1_modules-0.4.0-py3-none-any.whl.metadata\n",
      "  Using cached pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for rsa<5,>=3.1.4 from https://files.pythonhosted.org/packages/49/97/fa78e3d2f65c02c8e1268b9aba606569fe97f6c8f7c2d74394553347c145/rsa-4.9-py3-none-any.whl.metadata\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/2f/95/f9310f35376024e1086c59cbb438d319fc9a4ef853289ce7c661539edbd4/filelock-3.16.0-py3-none-any.whl.metadata\n",
      "  Using cached filelock-3.16.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for fsspec>=2023.5.0 from https://files.pythonhosted.org/packages/1d/a0/6aaea0c2fbea2f89bfd5db25fb1e3481896a423002ebe4e55288907a97a3/fsspec-2024.9.0-py3-none-any.whl.metadata\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.20.1)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for markdown-it-py>=2.2.0 from https://files.pythonhosted.org/packages/42/d7/1ec15b46af6af88f19b8e5ffea08fa375d433c998b8a7639e76935c14f1f/markdown_it_py-3.0.0-py3-none-any.whl.metadata\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.18.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for humanfriendly>=9.1 from https://files.pythonhosted.org/packages/f0/0f/310fb31e39e2d734ccaa2c0fb981ee41f7bd5056ce9bc29b2248bd569169/humanfriendly-10.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.4.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for mdurl~=0.1 from https://files.pythonhosted.org/packages/b3/38/89ba8ad64ae25be8de66a6d463314cf1eb366222074cfda9ee839c56a4b4/mdurl-0.1.2-py3-none-any.whl.metadata\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Obtaining dependency information for pyasn1<0.7.0,>=0.4.6 from https://files.pythonhosted.org/packages/23/7e/5f50d07d5e70a2addbccd90ac2950f81d1edd0783630651d9268d7f1db49/pyasn1-0.6.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Using cached langchain_chroma-0.1.3-py3-none-any.whl (10 kB)\n",
      "Using cached chromadb-0.5.3-py3-none-any.whl (559 kB)\n",
      "Using cached chroma_hnswlib-0.7.3-cp311-cp311-win_amd64.whl (151 kB)\n",
      "Using cached fastapi-0.114.0-py3-none-any.whl (94 kB)\n",
      "Using cached bcrypt-4.2.0-cp39-abi3-win_amd64.whl (151 kB)\n",
      "Using cached build-1.2.2-py3-none-any.whl (22 kB)\n",
      "Using cached grpcio-1.66.1-cp311-cp311-win_amd64.whl (4.3 MB)\n",
      "Using cached kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Using cached onnxruntime-1.19.2-cp311-cp311-win_amd64.whl (11.1 MB)\n",
      "Using cached opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl (17 kB)\n",
      "Using cached opentelemetry_proto-1.27.0-py3-none-any.whl (52 kB)\n",
      "Using cached opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl (11 kB)\n",
      "Using cached opentelemetry_instrumentation-0.48b0-py3-none-any.whl (29 kB)\n",
      "Using cached opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl (15 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n",
      "Using cached opentelemetry_util_http-0.48b0-py3-none-any.whl (6.9 kB)\n",
      "Using cached opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n",
      "Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Using cached posthog-3.6.5-py2.py3-none-any.whl (54 kB)\n",
      "Using cached starlette-0.38.5-py3-none-any.whl (71 kB)\n",
      "Using cached tokenizers-0.20.0-cp311-none-win_amd64.whl (2.3 MB)\n",
      "Using cached typer-0.12.5-py3-none-any.whl (47 kB)\n",
      "Using cached importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached google_auth-2.34.0-py2.py3-none-any.whl (200 kB)\n",
      "Using cached googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\n",
      "Using cached httptools-0.6.1-cp311-cp311-win_amd64.whl (55 kB)\n",
      "Using cached huggingface_hub-0.24.6-py3-none-any.whl (417 kB)\n",
      "Using cached importlib_metadata-8.4.0-py3-none-any.whl (26 kB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Using cached protobuf-4.25.4-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Using cached rich-13.8.0-py3-none-any.whl (241 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached watchfiles-0.24.0-cp311-none-win_amd64.whl (277 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached pyproject_hooks-1.1.0-py3-none-any.whl (9.2 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached uvicorn-0.30.6-py3-none-any.whl (62 kB)\n",
      "Using cached cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached filelock-3.16.0-py3-none-any.whl (16 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "Installing collected packages: shellingham, pyproject_hooks, pyasn1, protobuf, overrides, opentelemetry-util-http, oauthlib, mdurl, importlib-resources, importlib-metadata, humanfriendly, httptools, grpcio, fsspec, filelock, deprecated, chroma-hnswlib, cachetools, bcrypt, watchfiles, uvicorn, starlette, rsa, requests-oauthlib, pyasn1-modules, posthog, opentelemetry-proto, opentelemetry-api, markdown-it-py, huggingface-hub, googleapis-common-protos, coloredlogs, build, tokenizers, rich, opentelemetry-semantic-conventions, opentelemetry-instrumentation, opentelemetry-exporter-otlp-proto-common, onnxruntime, google-auth, fastapi, typer, opentelemetry-sdk, opentelemetry-instrumentation-asgi, kubernetes, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, chromadb, langchain-chroma\n",
      "Successfully installed bcrypt-4.2.0 build-1.2.2 cachetools-5.5.0 chroma-hnswlib-0.7.3 chromadb-0.5.3 coloredlogs-15.0.1 deprecated-1.2.14 fastapi-0.114.0 filelock-3.16.0 fsspec-2024.9.0 google-auth-2.34.0 googleapis-common-protos-1.65.0 grpcio-1.66.1 httptools-0.6.1 huggingface-hub-0.24.6 humanfriendly-10.0 importlib-metadata-8.4.0 importlib-resources-6.4.5 kubernetes-30.1.0 langchain-chroma-0.1.3 markdown-it-py-3.0.0 mdurl-0.1.2 oauthlib-3.2.2 onnxruntime-1.19.2 opentelemetry-api-1.27.0 opentelemetry-exporter-otlp-proto-common-1.27.0 opentelemetry-exporter-otlp-proto-grpc-1.27.0 opentelemetry-instrumentation-0.48b0 opentelemetry-instrumentation-asgi-0.48b0 opentelemetry-instrumentation-fastapi-0.48b0 opentelemetry-proto-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 opentelemetry-util-http-0.48b0 overrides-7.7.0 posthog-3.6.5 protobuf-4.25.4 pyasn1-0.6.0 pyasn1-modules-0.4.0 pyproject_hooks-1.1.0 requests-oauthlib-2.0.0 rich-13.8.0 rsa-4.9 shellingham-1.5.4 starlette-0.38.5 tokenizers-0.20.0 typer-0.12.5 uvicorn-0.30.6 watchfiles-0.24.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "# from langchain_groq import ChatGroq\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain_core.runnables import RunnablePassthrough\n",
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "# from langchain.llms import OpenAI\n",
    "# from dotenv import load_dotenv\n",
    "# import openai\n",
    "import os\n",
    "# import pandas as pd\n",
    "from docx2pdf import convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_type( filepath):\n",
    "        # file = ''\n",
    "        folderpath = os.path.dirname(filepath)\n",
    "        filename = os.path.basename(filepath)\n",
    "        if filename.endswith('.xlsx'):\n",
    "            csvname = filename.split('.')[0] + '.csv'\n",
    "            file = os.path.join(folderpath, csvname)\n",
    "            df = pd.read_excel(filepath)\n",
    "            df.to_csv(file)\n",
    "        elif filename.endswith('.docx'):\n",
    "            pdfname = filename.split('.')[0] + '.pdf'\n",
    "            file = os.path.join(folderpath, pdfname)\n",
    "            convert(filepath, file)\n",
    "        else: \n",
    "            file = filepath\n",
    "\n",
    "        return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader( filepath):\n",
    "        if filepath.endswith('.csv') or filepath.endswith('.docx'):\n",
    "            file = source_type(filepath)\n",
    "        else:\n",
    "            file = filepath\n",
    "        loader = None\n",
    "        if file.endswith('.csv'):\n",
    "            loader = CSVLoader(file_path=file)\n",
    "        if file.endswith('.pdf'):\n",
    "            loader = PyPDFLoader(file)\n",
    "        if 'http' in filepath:\n",
    "            loader = UnstructuredURLLoader(urls=[file])\n",
    "        if loader is not None:\n",
    "            data = loader.load()\n",
    "            return data\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file type or URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_loader(\"https://python.langchain.com/v0.2/docs/integrations/document_loaders/url/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Samruddhi More\\Desktop\\LLM BE Template\\datatalk_template\\jupyter_notebook\\minimal-document.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Obtaining dependency information for sentence_transformers from https://files.pythonhosted.org/packages/58/4b/922436953394e1bfda05e4bf1fe0e80f609770f256c59a9df7a9254f3e0d/sentence_transformers-3.0.1-py3-none-any.whl.metadata\n",
      "  Using cached sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers<5.0.0,>=4.34.0 (from sentence_transformers)\n",
      "  Obtaining dependency information for transformers<5.0.0,>=4.34.0 from https://files.pythonhosted.org/packages/75/35/07c9879163b603f0e464b0f6e6e628a2340cfc7cdc5ca8e7d52d776710d4/transformers-4.44.2-py3-none-any.whl.metadata\n",
      "  Using cached transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from sentence_transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from sentence_transformers) (2.4.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from sentence_transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from sentence_transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from sentence_transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from sentence_transformers) (0.24.6)\n",
      "Requirement already satisfied: Pillow in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from sentence_transformers) (10.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.16.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (1.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2024.5.15)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.6.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\samruddhi more\\desktop\\llm be template\\tempenv\\lib\\site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Using cached sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
      "Using cached transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "Installing collected packages: transformers, sentence_transformers\n",
      "Successfully installed sentence_transformers-3.0.1 transformers-4.44.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "                chunk_size=1000,\n",
    "                chunk_overlap=10,\n",
    "                length_function=len\n",
    "            )\n",
    "\n",
    "\n",
    "chunks = text_splitter.split_documents(data)\n",
    "embeddings = HuggingFaceBgeEmbeddings()\n",
    "vector_store = Chroma.from_documents(\n",
    "    chunks,\n",
    "    # collection_name=\"example_collection\",\n",
    "    embeddings,\n",
    "    persist_directory=\"./chromadb\",  # Where to save data locally, remove if not neccesary\n",
    ")\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='loader = PlaywrightURLLoader(urls=urls, remove_selectors=[\"header\", \"footer\"])\\n\\ndata = await loader.aload()\\n\\ndata[0]\\n\\nAPI Reference:PlaywrightURLLoader', metadata={'source': 'https://python.langchain.com/v0.2/docs/integrations/document_loaders/url/'}),\n",
       " Document(page_content='Playwright URL Loader\\u200b\\n\\nPlaywright is an open-source automation tool developed by Microsoft that allows you to programmatically control and automate web browsers. It is designed for end-to-end testing, scraping, and automating tasks across various web browsers such as Chromium, Firefox, and WebKit.\\n\\nThis covers how to load HTML documents from a list of URLs using the PlaywrightURLLoader.\\n\\nPlaywright enables reliable end-to-end testing for modern web apps.\\n\\nAs in the Selenium case, Playwright allows us to load and render the JavaScript pages.\\n\\nTo use the PlaywrightURLLoader, you have to install playwright and unstructured. Additionally, you have to install the Playwright Chromium browser:\\n\\n%pip install --upgrade --quiet playwright unstructured\\n\\n!playwright install\\n\\nCurrently, nly the async method supported:\\n\\nfrom langchain_community.document_loaders import PlaywrightURLLoader\\n\\nurls = [\\n    \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\",\\n    \"https://goo.gl/maps/NDSHwePEyaHMFGwh8\",\\n]', metadata={'source': 'https://python.langchain.com/v0.2/docs/integrations/document_loaders/url/'}),\n",
       " Document(page_content='Related\\u200b\\n\\nDocument loader conceptual guide\\n\\nDocument loader how-to guides\\n\\nEdit this page\\n\\nWas this page helpful?\\n\\nYou can also leave detailed feedback on GitHub.\\n\\nUnstructured URL Loader\\n\\nSelenium URL Loader\\n\\nPlaywright URL Loader\\n\\nRelated', metadata={'source': 'https://python.langchain.com/v0.2/docs/integrations/document_loaders/url/'}),\n",
       " Document(page_content='URL\\n\\nThis example covers how to load HTML documents from a list of URLs into the Document format that we can use downstream.\\n\\nUnstructured URL Loader\\u200b\\n\\nFor the examples below, please install the unstructured library and see this guide for more instructions on setting up Unstructured locally, including setting up required system dependencies:\\n\\n%pip install --upgrade --quiet unstructured\\n\\nfrom langchain_community.document_loaders import UnstructuredURLLoader\\n\\nurls = [\\n    \"https://www.understandingwar.org/backgrounder/russian-offensive-campaign-assessment-february-8-2023\",\\n    \"https://www.understandingwar.org/backgrounder/russian-offensive-campaign-assessment-february-9-2023\",\\n]\\n\\nAPI Reference:UnstructuredURLLoader\\n\\nPass in ssl_verify=False with headers=headers to get past ssl_verification errors.\\n\\nloader = UnstructuredURLLoader(urls=urls)\\n\\ndata = loader.load()\\n\\ndata[0]', metadata={'source': 'https://python.langchain.com/v0.2/docs/integrations/document_loaders/url/'})]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents('PlaywriteURL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
